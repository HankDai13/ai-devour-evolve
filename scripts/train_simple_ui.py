#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆç¾åŒ–è®­ç»ƒç•Œé¢
ä¸ä¾èµ–å¤æ‚çš„richåŠŸèƒ½ï¼Œä½¿ç”¨åŸºæœ¬çš„æ§åˆ¶å°ç¾åŒ–
"""
import sys
import os
from pathlib import Path
import numpy as np
import time
from collections import deque

# è·¯å¾„è®¾ç½®
root_dir = Path(__file__).parent.parent
build_dir = root_dir / "build" / "Release"
sys.path.insert(0, str(build_dir))
os.environ["PATH"] = f"{str(build_dir)};{os.environ['PATH']}"

import gobigger_env
from gobigger_gym_env import GoBiggerEnv

try:
    from stable_baselines3 import PPO
    from stable_baselines3.common.env_util import make_vec_env
    from stable_baselines3.common.vec_env import DummyVecEnv
    from stable_baselines3.common.callbacks import BaseCallback
    STABLE_BASELINES_AVAILABLE = True
except ImportError:
    print("âŒ éœ€è¦å®‰è£… stable-baselines3")
    exit(1)

class SimpleTrainingDisplay:
    """ç®€åŒ–ç‰ˆè®­ç»ƒæ˜¾ç¤ºå™¨"""
    
    def __init__(self, total_timesteps):
        self.total_timesteps = total_timesteps
        self.start_time = time.time()
        
        # è®­ç»ƒç»Ÿè®¡
        self.stats = {
            'ep_len_mean': 0,
            'ep_rew_mean': 0,
            'ep_score_mean': 0,
            'episodes_completed': 0,
            'best_score': 0,
            'current_timesteps': 0,
            'fps': 0,
            'time_elapsed': 0
        }
        
        self.episode_scores = deque(maxlen=100)
        
    def clear_screen(self):
        """æ¸…å±"""
        os.system('cls' if os.name == 'nt' else 'clear')
    
    def create_progress_bar(self, current, total, width=50):
        """åˆ›å»ºè¿›åº¦æ¡"""
        percent = current / total
        filled = int(width * percent)
        bar = 'â–ˆ' * filled + 'â–‘' * (width - filled)
        return f"[{bar}] {percent*100:.1f}%"
    
    def update_stats(self, timesteps, episode_info=None, logger_data=None):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats['current_timesteps'] = timesteps
        self.stats['time_elapsed'] = time.time() - self.start_time
        
        if self.stats['time_elapsed'] > 0:
            self.stats['fps'] = timesteps / self.stats['time_elapsed']
        
        # æ›´æ–°episodeä¿¡æ¯
        if episode_info:
            if 'final_score' in episode_info:
                score = episode_info['final_score']
                self.episode_scores.append(score)
                self.stats['episodes_completed'] += 1
                self.stats['best_score'] = max(self.stats['best_score'], score)
        
        # æ›´æ–°å¹³å‡å€¼
        if len(self.episode_scores) > 0:
            self.stats['ep_score_mean'] = np.mean(self.episode_scores)
        
        # ä»loggeræ›´æ–°è®­ç»ƒæŒ‡æ ‡
        if logger_data:
            if 'rollout/ep_len_mean' in logger_data:
                self.stats['ep_len_mean'] = logger_data['rollout/ep_len_mean']
            if 'rollout/ep_rew_mean' in logger_data:
                self.stats['ep_rew_mean'] = logger_data['rollout/ep_rew_mean']
    
    def display_training_status(self):
        """æ˜¾ç¤ºè®­ç»ƒçŠ¶æ€"""
        self.clear_screen()
        
        print("ğŸ¤– GoBigger Reinforcement Learning Training")
        print("=" * 60)
        print()
        
        # è¿›åº¦æ¡
        progress_bar = self.create_progress_bar(self.stats['current_timesteps'], self.total_timesteps)
        print(f"ğŸ“ˆ Training Progress: {progress_bar}")
        print(f"   Steps: {self.stats['current_timesteps']:,}/{self.total_timesteps:,}")
        print()
        
        # è®­ç»ƒç»Ÿè®¡è¡¨æ ¼
        print("ğŸ“Š Training Statistics:")
        print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print(f"â”‚ Episodes        â”‚ {self.stats['episodes_completed']:>15,} â”‚")
        print(f"â”‚ Best Score      â”‚ {self.stats['best_score']:>15.0f} â”‚")
        print(f"â”‚ Avg Score       â”‚ {self.stats['ep_score_mean']:>15.0f} â”‚")
        print(f"â”‚ Avg Reward      â”‚ {self.stats['ep_rew_mean']:>15.2f} â”‚")
        print(f"â”‚ Avg Length      â”‚ {self.stats['ep_len_mean']:>15.0f} â”‚")
        print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        print(f"â”‚ FPS             â”‚ {self.stats['fps']:>15.0f} â”‚")
        print(f"â”‚ Time Elapsed    â”‚ {self.stats['time_elapsed']:>15.0f}s â”‚")
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        print()
        
        # æœ€æ–°ä¿¡æ¯
        if len(self.episode_scores) > 0:
            latest_score = self.episode_scores[-1]
            print(f"ğŸ¯ Latest Episode Score: {latest_score:.0f}")
        
        # é¢„ä¼°å‰©ä½™æ—¶é—´
        if self.stats['fps'] > 0:
            remaining_steps = self.total_timesteps - self.stats['current_timesteps']
            eta_seconds = remaining_steps / self.stats['fps']
            eta_minutes = eta_seconds / 60
            print(f"â±ï¸  Estimated Time Remaining: {eta_minutes:.1f} minutes")
        
        print()
        print("ğŸ’¡ Tip: æŒ‰ Ctrl+C å¯ä»¥ä¸­æ–­è®­ç»ƒ")

class SimpleTrainingCallback(BaseCallback):
    """ç®€åŒ–ç‰ˆè®­ç»ƒå›è°ƒ"""
    
    def __init__(self, display, update_interval=5, verbose=1):
        super().__init__(verbose)
        self.display = display
        self.update_interval = update_interval
        self.last_update = 0
        
    def _on_step(self) -> bool:
        current_time = time.time()
        
        # å¤„ç†episodeç»“æŸä¿¡æ¯
        episode_info = None
        for info in self.locals['infos']:
            if 'final_score' in info:
                episode_info = info
                # ç«‹å³æ˜¾ç¤ºepisodeç»“æŸä¿¡æ¯
                score = info['final_score']
                score_delta = info.get('score_delta', 0)
                print(f"\rğŸ¯ Episode ç»“æŸ - åˆ†æ•°: {score:.0f} (å˜åŒ–: {score_delta:+.0f})")
                break
        
        # è·å–loggeræ•°æ®
        logger_data = None
        if hasattr(self.model, 'logger') and hasattr(self.model.logger, 'name_to_value'):
            logger_data = self.model.logger.name_to_value
        
        # æ›´æ–°ç»Ÿè®¡
        self.display.update_stats(self.num_timesteps, episode_info, logger_data)
        
        # å®šæœŸæ›´æ–°ç•Œé¢
        if current_time - self.last_update > self.update_interval:
            self.display.display_training_status()
            self.last_update = current_time
        
        return True

def create_env(config=None):
    """åˆ›å»ºè®­ç»ƒç¯å¢ƒ"""
    default_config = {
        'max_episode_steps': 1500,
    }
    if config:
        default_config.update(config)
    
    return GoBiggerEnv(default_config)

def train_with_simple_ui(total_timesteps=20000):
    """ä½¿ç”¨ç®€åŒ–ç•Œé¢è®­ç»ƒ"""
    print("ğŸš€ å¯åŠ¨ç®€åŒ–ç¾åŒ–ç•Œé¢è®­ç»ƒ")
    print()
    
    # åˆ›å»ºæ˜¾ç¤ºå™¨
    display = SimpleTrainingDisplay(total_timesteps)
    
    # åˆ›å»ºç¯å¢ƒå’Œæ¨¡å‹
    env = make_vec_env(lambda: create_env(), n_envs=1, vec_env_cls=DummyVecEnv)
    
    model = PPO(
        "MlpPolicy", 
        env,
        learning_rate=3e-4,
        n_steps=1024,
        batch_size=64,
        n_epochs=10,
        gamma=0.99,
        verbose=0,  # é™é»˜æ¨¡å¼
        tensorboard_log="./tensorboard_logs/"
    )
    
    # åˆ›å»ºå›è°ƒ
    callback = SimpleTrainingCallback(display, update_interval=3)
    
    try:
        # å¼€å§‹è®­ç»ƒ
        model.learn(
            total_timesteps=total_timesteps,
            callback=callback,
            tb_log_name="PPO_gobigger_simple"
        )
        
        # æœ€åæ˜¾ç¤ºä¸€æ¬¡å®Œæ•´çŠ¶æ€
        display.display_training_status()
        
    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        display.display_training_status()
    
    # ä¿å­˜æ¨¡å‹
    os.makedirs("models", exist_ok=True)
    model_path = "models/PPO_gobigger_simple.zip"
    model.save(model_path)
    
    print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")
    print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    print(f"  - å®ŒæˆEpisodes: {display.stats['episodes_completed']}")
    print(f"  - æœ€ä½³åˆ†æ•°: {display.stats['best_score']:.0f}")
    print(f"  - å¹³å‡åˆ†æ•°: {display.stats['ep_score_mean']:.0f}")
    print(f"  - è®­ç»ƒæ—¶é•¿: {display.stats['time_elapsed']:.0f}ç§’")
    
    return model

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ® GoBigger ç®€åŒ–ç¾åŒ–ç•Œé¢è®­ç»ƒå™¨")
    print("=" * 60)
    print()
    print("è®­ç»ƒé…ç½®:")
    print("  - ç®—æ³•: PPO")
    print("  - è®­ç»ƒæ­¥æ•°: 20,000")
    print("  - Episodeé•¿åº¦: 1,500")
    print("  - ç•Œé¢: ç®€åŒ–ç¾åŒ–ç•Œé¢")
    print()
    
    confirm = input("å¼€å§‹è®­ç»ƒ? (y/n): ").lower().strip()
    if confirm in ['y', 'yes', 'æ˜¯']:
        try:
            train_with_simple_ui(total_timesteps=20000)
        except Exception as e:
            print(f"\nâŒ è®­ç»ƒå‡ºé”™: {e}")
    else:
        print("ğŸ‘‹ å·²å–æ¶ˆè®­ç»ƒ")

if __name__ == "__main__":
    main()
