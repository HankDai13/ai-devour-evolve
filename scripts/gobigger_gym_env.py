#!/usr/bin/env python3
"""
GoBigger Gymnasium Environment Wrapper
å°†C++æ ¸å¿ƒå¼•æ“åŒ…è£…æˆæ ‡å‡†çš„Gymnasiumç¯å¢ƒ
"""
import sys
import os
import time
from pathlib import Path
import numpy as np

# æ™ºèƒ½è·¯å¾„æœç´¢ï¼šå¯»æ‰¾æœ‰æ•ˆçš„æ„å»ºç›®å½•
root_dir = Path(__file__).parent.parent
build_dir_candidates = [
    root_dir / "build" / "Release",
    root_dir / "build" / "Debug", 
    root_dir / "build",
    root_dir / "build-msvc" / "Release",
    root_dir / "build-msvc" / "Debug",
]

build_dir_found = None
for build_dir in build_dir_candidates:
    if build_dir.exists() and any(build_dir.iterdir()):
        sys.path.insert(0, str(build_dir))
        os.environ["PATH"] = f"{str(build_dir)};{os.environ['PATH']}"
        build_dir_found = build_dir
        print(f"âœ… æ‰¾åˆ°æ„å»ºç›®å½•: {build_dir}")
        break

if not build_dir_found:
    raise ImportError("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ„å»ºç›®å½•ã€‚è¯·ç¡®ä¿é¡¹ç›®å·²ç¼–è¯‘ã€‚")

try:
    import gobigger_env
    print("âœ… æˆåŠŸå¯¼å…¥ gobigger_env æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥ gobigger_env å¤±è´¥: {e}")
    print(f"æœç´¢è·¯å¾„: {build_dir_found}")
    raise

try:
    import gymnasium as gym
    from gymnasium import spaces
    GYMNASIUM_AVAILABLE = True
    print("âœ… ä½¿ç”¨ gymnasium åº“")
except ImportError:
    try:
        import gym
        from gym import spaces
        GYMNASIUM_AVAILABLE = False
        print("âœ… ä½¿ç”¨ gym åº“")
    except ImportError:
        print("âŒ éœ€è¦å®‰è£… gymnasium æˆ– gym")
        raise

class GoBiggerEnv(gym.Env if GYMNASIUM_AVAILABLE else gym.Env):
    """
    GoBiggerç¯å¢ƒçš„Gymnasiumé£æ ¼åŒ…è£…å™¨
    æä¾›æ ‡å‡†çš„reset()ã€step()ã€render()æ¥å£
    """
    
    def __init__(self, config=None):
        """åˆå§‹åŒ–ç¯å¢ƒ"""
        super().__init__()
        
        self.engine = gobigger_env.GameEngine()
        self.config = config or {}
        
        # å®šä¹‰åŠ¨ä½œç©ºé—´å’Œè§‚å¯Ÿç©ºé—´
        self.action_space = spaces.Box(
            low=np.array([-1.0, -1.0, 0], dtype=np.float32),
            high=np.array([1.0, 1.0, 2], dtype=np.float32),
            dtype=np.float32
        )
        
        # è§‚å¯Ÿç©ºé—´å¤§å°éœ€è¦ä¸ç‰¹å¾æå–ä¿æŒä¸€è‡´
        self.observation_space_shape = (400,)
        self.observation_space = spaces.Box(
            low=-np.inf,
            high=np.inf,
            shape=self.observation_space_shape,
            dtype=np.float32
        )
        
        # åŠ¨ä½œç©ºé—´å®šä¹‰ï¼ˆå…¼å®¹æ€§ä¿ç•™ï¼‰
        self.action_space_low = np.array([-1.0, -1.0, 0], dtype=np.float32)
        self.action_space_high = np.array([1.0, 1.0, 2], dtype=np.float32)
        
        # ç¯å¢ƒçŠ¶æ€
        self.current_obs = None
        self.episode_step = 0
        self.max_episode_steps = self.config.get('max_episode_steps', 2000)  # å¢åŠ é»˜è®¤æ­¥æ•°
        
        # å¥–åŠ±å‡½æ•°ä¼˜åŒ–ï¼šè¿½è¸ªåˆ†æ•°å˜åŒ–
        self.last_score = 0.0
        self.initial_score = 0.0  # è®°å½•åˆå§‹åˆ†æ•°
        self.final_score = 0.0    # è®°å½•æœ€ç»ˆåˆ†æ•°
        self.prev_observation = None
        
    def reset(self, seed=None, options=None):
        """é‡ç½®ç¯å¢ƒ"""
        if seed is not None:
            # è®¾ç½®éšæœºç§å­ï¼ˆå¦‚æœå¼•æ“æ”¯æŒï¼‰
            np.random.seed(seed)
        
        self.episode_step = 0
        self.episode_reward = 0.0  # é‡ç½®episodeç´¯ç§¯å¥–åŠ±
        self.current_obs = self.engine.reset()
        
        # åˆå§‹åŒ–å¥–åŠ±å‡½æ•°çŠ¶æ€
        if self.current_obs and self.current_obs.player_states:
            ps = list(self.current_obs.player_states.values())[0]
            self.last_score = ps.score
            self.initial_score = ps.score  # è®°å½•åˆå§‹åˆ†æ•°
        else:
            self.last_score = 0.0
            self.initial_score = 0.0

        self.final_score = 0.0  # é‡ç½®æœ€ç»ˆåˆ†æ•°
        self.prev_observation = self.current_obs
        
        # é‡ç½®å¢å¼ºå¥–åŠ±è®¡ç®—å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if hasattr(self, 'enhanced_reward_calculator'):
            self.enhanced_reward_calculator.reset()
            self.reward_components_history = []
        
        # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„gym
        if GYMNASIUM_AVAILABLE:
            return self._extract_features(), {}
        else:
            return self._extract_features()
    
    def step(self, action):
        """æ‰§è¡Œä¸€æ­¥åŠ¨ä½œ"""
        # ç¡®ä¿åŠ¨ä½œæ ¼å¼æ­£ç¡®å¹¶è¿›è¡Œè£å‰ª
        if isinstance(action, (list, tuple, np.ndarray)):
            if len(action) >= 3:
                # è£å‰ªåŠ¨ä½œåˆ°æœ‰æ•ˆèŒƒå›´
                move_x = float(np.clip(action[0], -1.0, 1.0))
                move_y = float(np.clip(action[1], -1.0, 1.0))
                action_type = int(np.round(np.clip(action[2], 0, 2)))
                cpp_action = gobigger_env.Action(move_x, move_y, action_type)
            else:
                cpp_action = gobigger_env.Action(0.0, 0.0, 0)
        else:
            cpp_action = action
        
        # æ‰§è¡ŒåŠ¨ä½œ
        self.prev_observation = self.current_obs
        self.current_obs = self.engine.step(cpp_action)
        self.episode_step += 1
        
        # è®¡ç®—å¥–åŠ±å’Œç»ˆæ­¢æ¡ä»¶ï¼ˆä¼ é€’åŸå§‹actionç”¨äºå¢å¼ºå¥–åŠ±è®¡ç®—ï¼‰
        reward = self._calculate_reward(action)
        terminated = self.engine.is_done()
        truncated = self.episode_step >= self.max_episode_steps
        
        # å‡†å¤‡infoå­—å…¸
        info = {}
        
        # ç´¯ç§¯episodeæ€»å¥–åŠ±ï¼ˆç”¨äºMonitorç»Ÿè®¡ï¼‰
        if not hasattr(self, 'episode_reward'):
            self.episode_reward = 0.0
        self.episode_reward += reward
        
        # å¦‚æœepisodeç»“æŸï¼Œè®°å½•æœ€ç»ˆåˆ†æ•°
        if terminated or truncated:
            if self.current_obs and self.current_obs.player_states:
                ps = list(self.current_obs.player_states.values())[0]
                self.final_score = ps.score
            else:
                self.final_score = self.last_score
            
            # MonitoræœŸæœ›çš„æ ‡å‡†é”®
            info['episode'] = {
                'r': self.episode_reward,                     # episodeæ€»å¥–åŠ±ï¼ˆç´¯ç§¯çš„stepå¥–åŠ±ï¼‰
                'l': self.episode_step,                       # episodeé•¿åº¦
                't': time.time()                              # æ—¶é—´æˆ³
            }
            
            # é¢å¤–çš„ç»Ÿè®¡ä¿¡æ¯
            info['final_score'] = self.final_score
            info['score_delta'] = self.final_score - self.initial_score
            info['episode_length'] = self.episode_step
        
        # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„gym
        if GYMNASIUM_AVAILABLE:
            return self._extract_features(), reward, terminated, truncated, info
        else:
            return self._extract_features(), reward, terminated or truncated, info
    
    def _extract_features(self):
        """ä»C++è§‚å¯Ÿä¸­æå–ç‰¹å¾å‘é‡ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        if not self.current_obs or not self.current_obs.player_states:
            return np.zeros(self.observation_space_shape, dtype=np.float32)
        
        # è·å–ç¬¬ä¸€ä¸ªç©å®¶çš„çŠ¶æ€
        ps = list(self.current_obs.player_states.values())[0]
        
        features = []
        
        # å…¨å±€ç‰¹å¾ (10ç»´) - æ”¹è¿›å½’ä¸€åŒ–
        gs = self.current_obs.global_state
        features.extend([
            gs.total_frame / self.max_episode_steps,  # å½’ä¸€åŒ–å¸§æ•°
            len(gs.leaderboard) / 10.0,               # å½’ä¸€åŒ–é˜Ÿä¼æ•°é‡
            ps.score / 10000.0,                       # å½’ä¸€åŒ–åˆ†æ•°
            float(ps.can_eject),                      # èƒ½å¦åçƒ
            float(ps.can_split),                      # èƒ½å¦åˆ†è£‚
        ])
        features.extend([0.0] * 5)  # é¢„ç•™5ä¸ªå…¨å±€ç‰¹å¾
        
        # è§†é‡çŸ©å½¢ (4ç»´) - æ”¹è¿›å½’ä¸€åŒ–
        features.extend([coord / 2000.0 for coord in ps.rectangle])
        
        # æ‰å¹³åŒ–å¯¹è±¡ç‰¹å¾ - æ”¹è¿›å½’ä¸€åŒ–å’Œæ•°æ®å¤„ç†
        # é£Ÿç‰©: 50ä¸ª Ã— 4ç»´ = 200ç»´
        food_count = 0
        for food in ps.food:
            if food_count >= 50:
                break
            # å½’ä¸€åŒ–åæ ‡å’ŒåŠå¾„
            features.extend([
                food[0] / 2000.0,   # xåæ ‡å½’ä¸€åŒ–
                food[1] / 2000.0,   # yåæ ‡å½’ä¸€åŒ–  
                food[2] / 10.0,     # åŠå¾„å½’ä¸€åŒ–
                2.0                 # ç±»å‹æ ‡è¯†
            ])
            food_count += 1
        # å¡«å……å‰©ä½™çš„é£Ÿç‰©æ§½ä½
        features.extend([0.0] * ((50 - food_count) * 4))
        
        # è†æ£˜: 20ä¸ª Ã— 4ç»´ = 80ç»´
        thorns_count = 0
        for thorns in ps.thorns:
            if thorns_count >= 20:
                break
            features.extend([
                thorns[0] / 2000.0,  # xåæ ‡å½’ä¸€åŒ–
                thorns[1] / 2000.0,  # yåæ ‡å½’ä¸€åŒ–
                thorns[2] / 100.0,   # åŠå¾„å½’ä¸€åŒ–
                3.0                  # ç±»å‹æ ‡è¯†
            ])
            thorns_count += 1
        # å¡«å……å‰©ä½™çš„è†æ£˜æ§½ä½
        features.extend([0.0] * ((20 - thorns_count) * 4))
        
        # å­¢å­: 10ä¸ª Ã— 4ç»´ = 40ç»´
        spore_count = 0
        for spore in ps.spore:
            if spore_count >= 10:
                break
            features.extend([
                spore[0] / 2000.0,   # xåæ ‡å½’ä¸€åŒ–
                spore[1] / 2000.0,   # yåæ ‡å½’ä¸€åŒ–
                spore[2] / 20.0,     # åŠå¾„å½’ä¸€åŒ–
                4.0                  # ç±»å‹æ ‡è¯†
            ])
            spore_count += 1
        # å¡«å……å‰©ä½™çš„å­¢å­æ§½ä½
        features.extend([0.0] * ((10 - spore_count) * 4))
        
        # æˆªæ–­æˆ–å¡«å……åˆ°å›ºå®šé•¿åº¦
        # æ€»è®¡: 10 + 4 + 200 + 80 + 40 = 334ç»´ï¼Œå¡«å……åˆ°400ç»´
        target_length = self.observation_space_shape[0]
        if len(features) > target_length:
            features = features[:target_length]
        elif len(features) < target_length:
            features.extend([0.0] * (target_length - len(features)))
        
        return np.array(features, dtype=np.float32)
    
    def _calculate_reward(self, action=None):
        """
        è®¡ç®—å¥–åŠ±ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰
        æ”¯æŒä¸¤ç§æ¨¡å¼ï¼šç®€å•æ¨¡å¼ï¼ˆåŸç‰ˆï¼‰å’Œå¢å¼ºæ¨¡å¼
        """
        # é€‰æ‹©å¥–åŠ±è®¡ç®—æ¨¡å¼
        use_enhanced_reward = self.config.get('use_enhanced_reward', False)
        
        if use_enhanced_reward and hasattr(self, 'enhanced_reward_calculator'):
            return self._calculate_enhanced_reward(action)
        else:
            return self._calculate_simple_reward()
    
    def _calculate_simple_reward(self):
        """
        è®¡ç®—ç®€å•å¥–åŠ±ï¼ˆåŸç‰ˆé€»è¾‘ï¼‰
        æ ¸å¿ƒæ€æƒ³ï¼šå¥–åŠ±åˆ†æ•°å¢é‡è€Œéç»å¯¹åˆ†æ•°ï¼Œé¿å…å¥–åŠ±ç¨€ç–æ€§é—®é¢˜
        """
        if not self.current_obs or not self.current_obs.player_states:
            return -5.0  # æ— æ•ˆçŠ¶æ€æƒ©ç½š

        ps = list(self.current_obs.player_states.values())[0]
        
        # 1. åˆ†æ•°å¢é‡å¥–åŠ±ï¼ˆä¸»è¦å¥–åŠ±æ¥æºï¼‰
        score_delta = ps.score - self.last_score
        score_reward = score_delta / 100.0  # ç¼©æ”¾ç³»æ•°ï¼Œé¿å…å¥–åŠ±è¿‡å¤§
        
        # 2. æ—¶é—´æƒ©ç½šï¼ˆé¼“åŠ±å¿«é€Ÿå†³ç­–ï¼‰
        time_penalty = -0.001
        
        # 3. æ­»äº¡æƒ©ç½šï¼ˆå…³é”®æƒ©ç½šï¼‰
        death_penalty = 0.0
        if self.engine.is_done():
            death_penalty = -10.0
        
        # 4. ç”Ÿå­˜å¥–åŠ±ï¼ˆå°å¹…æ­£å¥–åŠ±ï¼‰
        survival_reward = 0.01 if not self.engine.is_done() else 0.0
        
        # 5. å°ºå¯¸å¥–åŠ±ï¼ˆå¯é€‰ï¼‰
        size_reward = 0.0
        if self.prev_observation and self.prev_observation.player_states:
            prev_ps = list(self.prev_observation.player_states.values())[0]
            # åŸºäºcloneåˆ—è¡¨é•¿åº¦çš„å¥–åŠ±ï¼ˆç»†èƒæ•°é‡å˜åŒ–ï¼‰
            if hasattr(ps, 'clone') and hasattr(prev_ps, 'clone'):
                current_cells = len(ps.clone) if isinstance(ps.clone, list) else 1
                prev_cells = len(prev_ps.clone) if isinstance(prev_ps.clone, list) else 1
                cell_delta = current_cells - prev_cells
                size_reward = cell_delta * 0.1
        
        # æ€»å¥–åŠ±è®¡ç®—
        total_reward = (score_reward + time_penalty + death_penalty + 
                       survival_reward + size_reward)
        
        # æ›´æ–°ä¸Šä¸€å¸§åˆ†æ•°
        self.last_score = ps.score
        
        return total_reward
    
    def _calculate_enhanced_reward(self, action):
        """
        è®¡ç®—å¢å¼ºå¥–åŠ±ï¼ˆä½¿ç”¨å¢å¼ºå¥–åŠ±ç³»ç»Ÿï¼‰
        """
        if not hasattr(self, 'enhanced_reward_calculator'):
            # æ‡’åŠ è½½å¢å¼ºå¥–åŠ±è®¡ç®—å™¨
            try:
                from enhanced_reward_system import EnhancedRewardCalculator
                self.enhanced_reward_calculator = EnhancedRewardCalculator(self.config)
                self.reward_components_history = []
            except ImportError:
                print("âš ï¸  è­¦å‘Š: æ— æ³•å¯¼å…¥å¢å¼ºå¥–åŠ±ç³»ç»Ÿï¼Œå›é€€åˆ°ç®€å•å¥–åŠ±")
                return self._calculate_simple_reward()
        
        # ä½¿ç”¨å¢å¼ºå¥–åŠ±ç³»ç»Ÿè®¡ç®—å¥–åŠ±
        total_reward, reward_components = self.enhanced_reward_calculator.calculate_reward(
            self.current_obs, 
            self.prev_observation, 
            action or [0, 0, 0],  # é»˜è®¤åŠ¨ä½œ
            self.episode_step
        )
        
        # è®°å½•å¥–åŠ±ç»„ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        self.reward_components_history.append({
            'step': self.episode_step,
            'total_reward': total_reward,
            'components': reward_components
        })
        
        # ä¿æŒå†å²é•¿åº¦
        if len(self.reward_components_history) > 50:
            self.reward_components_history.pop(0)
        
        # æ›´æ–°ä¸Šä¸€å¸§åˆ†æ•°ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        if self.current_obs and self.current_obs.player_states:
            ps = list(self.current_obs.player_states.values())[0]
            self.last_score = ps.score
        
        return total_reward
    
    def render(self, mode='human'):
        """æ¸²æŸ“ç¯å¢ƒï¼ˆå¯é€‰å®ç°ï¼‰"""
        if mode == 'human':
            print(f"Frame: {self.current_obs.global_state.total_frame if self.current_obs else 0}")
            if self.current_obs and self.current_obs.player_states:
                ps = list(self.current_obs.player_states.values())[0]
                score_delta = ps.score - self.last_score
                print(f"Score: {ps.score:.2f} (Î”{score_delta:+.2f}), "
                      f"Can eject: {ps.can_eject}, Can split: {ps.can_split}")
    
    def close(self):
        """æ¸…ç†èµ„æº"""
        print("ğŸ”š ç¯å¢ƒå…³é—­")
        pass

def demo_gymnasium_usage():
    """æ¼”ç¤ºæ ‡å‡†Gymnasiumä½¿ç”¨æ–¹å¼ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
    print("\n" + "="*50)
    print("ğŸ® GoBigger Gymnasium ç¯å¢ƒæ¼”ç¤º (ä¼˜åŒ–ç‰ˆ)")
    print("="*50 + "\n")
    
    # åˆ›å»ºç¯å¢ƒ
    env = GoBiggerEnv({'max_episode_steps': 100})
    
    # æ£€æŸ¥ç¯å¢ƒï¼ˆå¦‚æœå®‰è£…äº†stable-baselines3ï¼‰
    try:
        from stable_baselines3.common.env_checker import check_env
        print("ğŸ” ä½¿ç”¨ stable-baselines3 æ£€æŸ¥ç¯å¢ƒ...")
        check_env(env)
        print("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡ï¼\n")
    except ImportError:
        print("âš ï¸ æœªå®‰è£… stable-baselines3ï¼Œè·³è¿‡ç¯å¢ƒæ£€æŸ¥\n")
    
    # é‡ç½®ç¯å¢ƒ
    if GYMNASIUM_AVAILABLE:
        obs, info = env.reset()
    else:
        obs = env.reset()
        info = {}
    
    print(f"ğŸ ç¯å¢ƒé‡ç½®å®Œæˆ")
    print(f"   è§‚å¯Ÿç©ºé—´: {env.observation_space}")
    print(f"   åŠ¨ä½œç©ºé—´: {env.action_space}")
    print(f"   è§‚å¯Ÿç»´åº¦: {obs.shape}")
    print(f"   è§‚å¯Ÿå‰10ä¸ªå€¼: {obs[:10]}")
    print()
    
    # è¿è¡Œå‡ æ­¥
    total_reward = 0
    for step in range(10):
        # éšæœºåŠ¨ä½œ
        action = env.action_space.sample()
        
        if GYMNASIUM_AVAILABLE:
            obs, reward, terminated, truncated, info = env.step(action)
            done = terminated or truncated
        else:
            obs, reward, done, info = env.step(action)
            terminated, truncated = done, False
        
        total_reward += reward
        
        print(f"æ­¥éª¤ {step+1:02d}: "
              f"åŠ¨ä½œ=[{action[0]:.2f}, {action[1]:.2f}, {int(np.round(action[2]))}], "
              f"å¥–åŠ±={reward:.4f}, "
              f"ç´¯è®¡å¥–åŠ±={total_reward:.4f}, "
              f"ç»“æŸ={done}")
        
        if done:
            print(f"\nğŸ å›åˆç»“æŸ (ç¬¬{step+1}æ­¥)")
            break
    
    print(f"\nâœ… æ¼”ç¤ºå®Œæˆï¼")
    print(f"   æœ€ç»ˆç´¯è®¡å¥–åŠ±: {total_reward:.4f}")
    print(f"   å¹³å‡æ­¥éª¤å¥–åŠ±: {total_reward/(step+1):.4f}")
    
    env.close()

if __name__ == "__main__":
    demo_gymnasium_usage()