#!/usr/bin/env python3
"""
å¿«é€ŸéªŒè¯å¯¼å‡ºçš„AIæ¨¡å‹æ˜¯å¦å·¥ä½œæ­£å¸¸
"""

import torch
import numpy as np
import json
import os

def test_pytorch_model():
    """æµ‹è¯•PyTorch TorchScriptæ¨¡å‹"""
    model_path = "assets/ai_models/exported_models/ai_model_traced.pt"
    
    if not os.path.exists(model_path):
        print(f"âŒ Model file not found: {model_path}")
        return False
    
    try:
        print(f"ğŸ”„ Loading PyTorch model: {model_path}")
        model = torch.jit.load(model_path)
        model.eval()
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥ (1æ‰¹æ¬¡, 400ç»´è§‚æµ‹)
        test_input = torch.randn(1, 400)
        print(f"ğŸ“¥ Test input shape: {test_input.shape}")
        
        # æ‰§è¡Œæ¨ç†
        with torch.no_grad():
            output = model(test_input)
        
        # å¤„ç†å¯èƒ½çš„å…ƒç»„è¾“å‡º
        if isinstance(output, tuple):
            output = output[0]  # å–ç¬¬ä¸€ä¸ªå…ƒç´ 
        
        print(f"ğŸ“¤ Output shape: {output.shape}")
        print(f"ğŸ“¤ Output values: {output.squeeze().tolist()}")
        
        # è§£æè¾“å‡º
        dx, dy, action_type_raw = output.squeeze().tolist()
        
        # å¤„ç†è¾“å‡º
        dx = max(-1.0, min(1.0, dx))
        dy = max(-1.0, min(1.0, dy))
        
        if action_type_raw >= 1.5:
            action_type = "EJECT"
        elif action_type_raw >= 0.5:
            action_type = "SPLIT"
        else:
            action_type = "MOVE"
        
        print(f"âœ… PyTorch model test successful!")
        print(f"   ğŸ¯ Action: {action_type}")
        print(f"   ğŸ“ Direction: dx={dx:.3f}, dy={dy:.3f}")
        print(f"   ğŸ”¢ Raw action type: {action_type_raw:.3f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ PyTorch model test failed: {e}")
        return False

def test_onnx_model():
    """æµ‹è¯•ONNXæ¨¡å‹"""
    model_path = "assets/ai_models/exported_models/ai_model.onnx"
    
    if not os.path.exists(model_path):
        print(f"âŒ ONNX model file not found: {model_path}")
        return False
    
    try:
        import onnxruntime as ort
        
        print(f"ğŸ”„ Loading ONNX model: {model_path}")
        session = ort.InferenceSession(model_path)
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_input = np.random.randn(1, 400).astype(np.float32)
        print(f"ğŸ“¥ Test input shape: {test_input.shape}")
        
        # æ‰§è¡Œæ¨ç†
        input_name = session.get_inputs()[0].name
        output_name = session.get_outputs()[0].name
        
        result = session.run([output_name], {input_name: test_input})
        output = result[0]
        
        print(f"ğŸ“¤ Output shape: {output.shape}")
        print(f"ğŸ“¤ Output values: {output.squeeze().tolist()}")
        
        # è§£æè¾“å‡º
        dx, dy, action_type_raw = output.squeeze().tolist()
        
        # å¤„ç†è¾“å‡º
        dx = max(-1.0, min(1.0, dx))
        dy = max(-1.0, min(1.0, dy))
        
        if action_type_raw >= 1.5:
            action_type = "EJECT"
        elif action_type_raw >= 0.5:
            action_type = "SPLIT"
        else:
            action_type = "MOVE"
        
        print(f"âœ… ONNX model test successful!")
        print(f"   ğŸ¯ Action: {action_type}")
        print(f"   ğŸ“ Direction: dx={dx:.3f}, dy={dy:.3f}")
        print(f"   ğŸ”¢ Raw action type: {action_type_raw:.3f}")
        
        return True
        
    except ImportError:
        print("âš ï¸ ONNX Runtime not installed, skipping ONNX test")
        print("   Install with: pip install onnxruntime")
        return False
    except Exception as e:
        print(f"âŒ ONNX model test failed: {e}")
        return False

def test_model_info():
    """éªŒè¯æ¨¡å‹ä¿¡æ¯æ–‡ä»¶"""
    info_path = "assets/ai_models/exported_models/model_info.json"
    
    if not os.path.exists(info_path):
        print(f"âŒ Model info file not found: {info_path}")
        return False
    
    try:
        print(f"ğŸ”„ Loading model info: {info_path}")
        with open(info_path, 'r') as f:
            info = json.load(f)
        
        print(f"âœ… Model info loaded successfully!")
        print(f"   ğŸ“‹ Model type: {info.get('model_type', 'Unknown')}")
        print(f"   ğŸ“ Observation space: {info.get('observation_space_size', 'Unknown')}")
        print(f"   ğŸ® Action space: {info.get('action_space', {})}")
        print(f"   ğŸ“ Notes: {len(info.get('usage_notes', []))} usage notes")
        
        return True
        
    except Exception as e:
        print(f"âŒ Model info test failed: {e}")
        return False

def main():
    print("ğŸ¤– AI Model Validation Test")
    print("=" * 50)
    
    # æ£€æŸ¥å½“å‰ç›®å½•
    current_dir = os.getcwd()
    print(f"ğŸ“ Current directory: {current_dir}")
    
    if not os.path.exists("assets/ai_models/exported_models"):
        print("âŒ Models directory not found!")
        print("   Please run this script from the project root directory")
        return
    
    print("\nğŸ§ª Running model tests...")
    
    # æµ‹è¯•æ¨¡å‹ä¿¡æ¯
    print("\n1ï¸âƒ£ Testing model info...")
    test_model_info()
    
    # æµ‹è¯•PyTorchæ¨¡å‹
    print("\n2ï¸âƒ£ Testing PyTorch model...")
    pytorch_ok = test_pytorch_model()
    
    # æµ‹è¯•ONNXæ¨¡å‹
    print("\n3ï¸âƒ£ Testing ONNX model...")
    onnx_ok = test_onnx_model()
    
    # æ€»ç»“
    print("\nğŸ“Š Test Summary:")
    print("=" * 50)
    print(f"PyTorch Model: {'âœ… PASS' if pytorch_ok else 'âŒ FAIL'}")
    print(f"ONNX Model: {'âœ… PASS' if onnx_ok else 'âŒ FAIL'}")
    
    if pytorch_ok:
        print("\nğŸ‰ At least PyTorch model is working!")
        print("   Ready for C++ integration with LibTorch")
    else:
        print("\nâš ï¸ PyTorch model failed!")
        print("   Please check model export process")

if __name__ == "__main__":
    main()
