#!/usr/bin/env python3
"""
å¢å¼ºå¥–åŠ±ç³»ç»ŸæˆåŠŸæ¡ˆä¾‹æ¼”ç¤º
======================

é€šè¿‡æ›´é•¿çš„è®­ç»ƒæ—¶é—´å’Œæ›´å¤šçš„episodeæ¥å±•ç¤ºå¢å¼ºå¥–åŠ±ç³»ç»Ÿçš„æ•ˆæœã€‚
æ­¤è„šæœ¬ä¼šè¿è¡Œæ›´é•¿æ—¶é—´çš„æµ‹è¯•ï¼Œæ›´æœ‰å¯èƒ½è§‚å¯Ÿåˆ°åˆ†æ•°å¢é•¿ã€‚

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024å¹´
"""

import sys
import os
import numpy as np
import time

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

from gobigger_gym_env import GoBiggerEnv

def run_extended_demo():
    """è¿è¡Œæ‰©å±•æ¼”ç¤ºï¼Œæ›´æœ‰å¯èƒ½è§‚å¯Ÿåˆ°åˆ†æ•°å¢é•¿"""
    print("ğŸ® å¢å¼ºå¥–åŠ±ç³»ç»Ÿæ‰©å±•æ¼”ç¤º")
    print("=" * 50)
    print("è¿è¡Œæ›´é•¿çš„episodeä»¥è§‚å¯Ÿåˆ†æ•°å¢é•¿å’Œå¥–åŠ±å·®å¼‚...")
    print("")
    
    # é…ç½®ï¼šæ›´é•¿çš„episodeï¼Œå¢å¼ºå¥–åŠ±
    config = {
        'max_episode_steps': 500,  # æ›´é•¿çš„episode
        'use_enhanced_reward': True,
        'enhanced_reward_weights': {
            'score_growth': 3.0,        # æé«˜åˆ†æ•°å¥–åŠ±æƒé‡ä»¥ä¾¿è§‚å¯Ÿ
            'efficiency': 2.0,          
            'exploration': 1.0,         
            'strategic_split': 1.5,     
            'food_density': 1.2,        
            'survival': 0.01,           
            'time_penalty': -0.0005,    # å‡å°‘æ—¶é—´æƒ©ç½š
            'death_penalty': -15.0,     
        }
    }
    
    env = GoBiggerEnv(config)
    
    successful_episodes = []
    total_episodes = 5
    
    for episode in range(total_episodes):
        print(f"\nğŸ“Š Episode {episode + 1}/{total_episodes}")
        print("-" * 30)
        
        obs = env.reset()
        episode_reward = 0.0
        step_count = 0
        reward_history = []
        score_history = []
        
        # è®°å½•åˆå§‹çŠ¶æ€
        if env.current_obs and env.current_obs.player_states:
            initial_score = list(env.current_obs.player_states.values())[0].score
            max_score = initial_score
            score_increases = 0
        else:
            initial_score = 0.0
            max_score = 0.0
            score_increases = 0
        
        start_time = time.time()
        
        # è¿è¡Œepisodeï¼ˆæ›´é•¿æ—¶é—´ï¼‰
        for step in range(500):  # æœ€å¤š500æ­¥
            # ç”ŸæˆéšæœºåŠ¨ä½œ
            action = env.action_space.sample()
            
            # è®°å½•æ­¥éª¤å‰åˆ†æ•°
            if env.current_obs and env.current_obs.player_states:
                score_before = list(env.current_obs.player_states.values())[0].score
            else:
                score_before = initial_score
            
            # æ‰§è¡ŒåŠ¨ä½œ
            obs, reward, terminated, truncated, info = env.step(action)
            episode_reward += reward
            step_count += 1
            
            # è®°å½•æ­¥éª¤ååˆ†æ•°
            if env.current_obs and env.current_obs.player_states:
                score_after = list(env.current_obs.player_states.values())[0].score
            else:
                score_after = score_before
            
            reward_history.append(reward)
            score_history.append(score_after)
            
            # æ£€æŸ¥åˆ†æ•°å¢é•¿
            if score_after > score_before:
                score_increases += 1
                print(f"  æ­¥éª¤ {step + 1:3d}: ğŸ¯ åˆ†æ•°å¢é•¿! "
                      f"{score_before:.1f} â†’ {score_after:.1f} (å¥–åŠ±: {reward:+.4f})")
                
                # æ˜¾ç¤ºå¥–åŠ±ç»„ä»¶åˆ†è§£ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if hasattr(env, 'reward_components_history') and env.reward_components_history:
                    components = env.reward_components_history[-1]['components']
                    if components:
                        print(f"               å¥–åŠ±ç»„ä»¶: ", end="")
                        for comp, val in components.items():
                            if abs(val) > 0.001:  # åªæ˜¾ç¤ºæœ‰æ„ä¹‰çš„ç»„ä»¶
                                weighted = val * config['enhanced_reward_weights'].get(comp, 1.0)
                                print(f"{comp}={weighted:+.3f} ", end="")
                        print()
            
            # æ›´æ–°æœ€é«˜åˆ†æ•°
            if score_after > max_score:
                max_score = score_after
            
            # æ¯50æ­¥æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if step > 0 and step % 50 == 0:
                current_score = score_after
                avg_reward = np.mean(reward_history[-50:])
                print(f"  æ­¥éª¤ {step:3d}: å½“å‰åˆ†æ•°={current_score:.1f}, "
                      f"å¹³å‡å¥–åŠ±={avg_reward:+.4f}, åˆ†æ•°å¢é•¿æ¬¡æ•°={score_increases}")
            
            # æ£€æŸ¥æ˜¯å¦ç»“æŸ
            if terminated or truncated:
                break
        
        # Episodeæ€»ç»“
        duration = time.time() - start_time
        final_score = info.get('final_score', max_score)
        score_delta = final_score - initial_score
        avg_reward = np.mean(reward_history) if reward_history else 0.0
        
        print(f"\n  ğŸ“‹ Episode {episode + 1} æ€»ç»“:")
        print(f"     åˆå§‹åˆ†æ•°: {initial_score:.1f}")
        print(f"     æœ€ç»ˆåˆ†æ•°: {final_score:.1f}")
        print(f"     åˆ†æ•°å¢é•¿: {score_delta:+.1f}")
        print(f"     æœ€é«˜åˆ†æ•°: {max_score:.1f}")
        print(f"     æ€»å¥–åŠ±: {episode_reward:.4f}")
        print(f"     å¹³å‡å¥–åŠ±: {avg_reward:.4f}")
        print(f"     æ­¥æ•°: {step_count}")
        print(f"     åˆ†æ•°å¢é•¿æ¬¡æ•°: {score_increases}")
        print(f"     æŒç»­æ—¶é—´: {duration:.1f}ç§’")
        
        # å¦‚æœæœ‰åˆ†æ•°å¢é•¿ï¼Œè®°å½•ä¸ºæˆåŠŸæ¡ˆä¾‹
        if score_delta > 0:
            successful_episodes.append({
                'episode': episode + 1,
                'initial_score': initial_score,
                'final_score': final_score,
                'score_delta': score_delta,
                'total_reward': episode_reward,
                'avg_reward': avg_reward,
                'steps': step_count,
                'score_increases': score_increases,
                'duration': duration
            })
            print(f"     âœ… æˆåŠŸæ¡ˆä¾‹ï¼")
        else:
            print(f"     âš ï¸  æ— åˆ†æ•°å¢é•¿")
    
    # æœ€ç»ˆæ€»ç»“
    print(f"\nğŸ¯ æ‰©å±•æ¼”ç¤ºæ€»ç»“")
    print("=" * 50)
    print(f"æ€»Episodes: {total_episodes}")
    print(f"æˆåŠŸEpisodesï¼ˆæœ‰åˆ†æ•°å¢é•¿ï¼‰: {len(successful_episodes)}")
    
    if successful_episodes:
        print(f"\nğŸ“Š æˆåŠŸæ¡ˆä¾‹ç»Ÿè®¡:")
        total_score_delta = sum(ep['score_delta'] for ep in successful_episodes)
        avg_score_delta = total_score_delta / len(successful_episodes)
        max_score_delta = max(ep['score_delta'] for ep in successful_episodes)
        avg_reward = np.mean([ep['avg_reward'] for ep in successful_episodes])
        avg_steps = np.mean([ep['steps'] for ep in successful_episodes])
        avg_increases = np.mean([ep['score_increases'] for ep in successful_episodes])
        
        print(f"  å¹³å‡åˆ†æ•°å¢é•¿: {avg_score_delta:.1f}")
        print(f"  æœ€å¤§åˆ†æ•°å¢é•¿: {max_score_delta:.1f}")
        print(f"  å¹³å‡å¥–åŠ±: {avg_reward:.4f}")
        print(f"  å¹³å‡æ­¥æ•°: {avg_steps:.1f}")
        print(f"  å¹³å‡åˆ†æ•°å¢é•¿æ¬¡æ•°: {avg_increases:.1f}")
        
        print(f"\nğŸ“ˆ æœ€ä½³æ¡ˆä¾‹:")
        best_episode = max(successful_episodes, key=lambda x: x['score_delta'])
        print(f"  Episode {best_episode['episode']}: "
              f"åˆ†æ•°å¢é•¿ {best_episode['score_delta']:+.1f} "
              f"({best_episode['initial_score']:.1f} â†’ {best_episode['final_score']:.1f})")
        print(f"  æ€»å¥–åŠ±: {best_episode['total_reward']:.4f}")
        print(f"  åˆ†æ•°å¢é•¿æ¬¡æ•°: {best_episode['score_increases']}")
        
    else:
        print("âš ï¸  æ²¡æœ‰è§‚å¯Ÿåˆ°åˆ†æ•°å¢é•¿çš„episode")
        print("   è¿™å¯èƒ½æ˜¯å› ä¸ºï¼š")
        print("   1. éšæœºåŠ¨ä½œç­–ç•¥æ•ˆç‡è¾ƒä½")
        print("   2. éœ€è¦æ›´é•¿çš„è®­ç»ƒæ—¶é—´")
        print("   3. å¯ä»¥å°è¯•ä½¿ç”¨å®é™…çš„RLç®—æ³•è€ŒééšæœºåŠ¨ä½œ")
    
    env.close()
    print(f"\nâœ… æ‰©å±•æ¼”ç¤ºå®Œæˆï¼")

def compare_systems_extended():
    """æ‰©å±•çš„ç³»ç»Ÿå¯¹æ¯”ï¼Œä½¿ç”¨æ›´é•¿æ—¶é—´"""
    print(f"\nâš–ï¸  æ‰©å±•ç³»ç»Ÿå¯¹æ¯”æµ‹è¯•")
    print("=" * 50)
    
    configs = {
        'ç®€å•å¥–åŠ±': {
            'max_episode_steps': 200,
            'use_enhanced_reward': False
        },
        'å¢å¼ºå¥–åŠ±': {
            'max_episode_steps': 200,
            'use_enhanced_reward': True,
            'enhanced_reward_weights': {
                'score_growth': 2.0,
                'efficiency': 1.5,
                'exploration': 0.8,
                'strategic_split': 1.5,
                'food_density': 1.0,
                'survival': 0.01,
                'time_penalty': -0.0005,
                'death_penalty': -15.0,
            }
        }
    }
    
    results = {}
    
    for system_name, config in configs.items():
        print(f"\nğŸ§ª æµ‹è¯• {system_name} ç³»ç»Ÿï¼ˆæ‰©å±•ç‰ˆï¼‰...")
        
        env = GoBiggerEnv(config)
        
        episode_rewards = []
        episode_scores = []
        score_deltas = []
        successful_episodes = 0
        
        # è¿è¡Œæ›´å¤šepisode
        for episode in range(5):
            obs = env.reset()
            episode_reward = 0.0
            
            if env.current_obs and env.current_obs.player_states:
                initial_score = list(env.current_obs.player_states.values())[0].score
            else:
                initial_score = 0.0
            
            # è¿è¡Œæ›´é•¿æ—¶é—´
            for step in range(200):
                action = env.action_space.sample()
                obs, reward, terminated, truncated, info = env.step(action)
                episode_reward += reward
                
                if terminated or truncated:
                    break
            
            final_score = info.get('final_score', initial_score)
            score_delta = final_score - initial_score
            
            episode_rewards.append(episode_reward)
            episode_scores.append(final_score)
            score_deltas.append(score_delta)
            
            if score_delta > 0:
                successful_episodes += 1
            
            print(f"  Episode {episode + 1}: "
                  f"å¥–åŠ±={episode_reward:.4f}, "
                  f"åˆ†æ•°={final_score:.1f} (Î”{score_delta:+.1f})")
        
        env.close()
        
        results[system_name] = {
            'avg_reward': np.mean(episode_rewards),
            'std_reward': np.std(episode_rewards),
            'avg_score': np.mean(episode_scores),
            'avg_score_delta': np.mean(score_deltas),
            'max_score_delta': max(score_deltas),
            'successful_episodes': successful_episodes,
            'success_rate': successful_episodes / len(episode_rewards) * 100
        }
    
    # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    print(f"\nğŸ“Š æ‰©å±•å¯¹æ¯”ç»“æœ:")
    print(f"{'æŒ‡æ ‡':<20} {'ç®€å•å¥–åŠ±':<15} {'å¢å¼ºå¥–åŠ±':<15} {'æ”¹è¿›':<10}")
    print("-" * 70)
    
    simple = results['ç®€å•å¥–åŠ±']
    enhanced = results['å¢å¼ºå¥–åŠ±']
    
    metrics = [
        ('å¹³å‡å¥–åŠ±', 'avg_reward'),
        ('å¥–åŠ±æ ‡å‡†å·®', 'std_reward'),
        ('å¹³å‡åˆ†æ•°', 'avg_score'),
        ('å¹³å‡åˆ†æ•°å¢é•¿', 'avg_score_delta'),
        ('æœ€å¤§åˆ†æ•°å¢é•¿', 'max_score_delta'),
        ('æˆåŠŸç‡(%)', 'success_rate')
    ]
    
    for name, key in metrics:
        simple_val = simple[key]
        enhanced_val = enhanced[key]
        
        if simple_val != 0:
            improvement = f"{((enhanced_val - simple_val) / abs(simple_val) * 100):+.1f}%"
        else:
            improvement = "N/A" if enhanced_val == 0 else "+âˆ"
        
        print(f"{name:<20} {simple_val:<15.3f} {enhanced_val:<15.3f} {improvement:<10}")
    
    # ç»“è®º
    print(f"\nğŸ¯ æµ‹è¯•ç»“è®º:")
    if enhanced['success_rate'] > simple['success_rate']:
        print(f"âœ… å¢å¼ºå¥–åŠ±ç³»ç»Ÿè¡¨ç°æ›´å¥½ï¼š")
        print(f"   - æˆåŠŸç‡æé«˜ {enhanced['success_rate'] - simple['success_rate']:.1f}%")
        print(f"   - å¹³å‡åˆ†æ•°å¢é•¿æé«˜ {enhanced['avg_score_delta'] - simple['avg_score_delta']:+.1f}")
    elif enhanced['success_rate'] == simple['success_rate']:
        print(f"âš–ï¸  ä¸¤ä¸ªç³»ç»Ÿè¡¨ç°ç›¸è¿‘ï¼Œå¯èƒ½éœ€è¦æ›´é•¿çš„æµ‹è¯•æ—¶é—´")
    else:
        print(f"âš ï¸  ç®€å•å¥–åŠ±ç³»ç»Ÿåœ¨æ­¤æµ‹è¯•ä¸­è¡¨ç°æ›´å¥½")
        print(f"   è¿™å¯èƒ½æ˜¯ç”±äºéšæœºåŠ¨ä½œå’ŒçŸ­æ—¶é—´æµ‹è¯•çš„é™åˆ¶")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¢å¼ºå¥–åŠ±ç³»ç»Ÿæ·±åº¦æµ‹è¯•")
    print("=" * 60)
    
    try:
        # æ‰©å±•æ¼”ç¤º
        run_extended_demo()
        
        # æ‰©å±•å¯¹æ¯”
        compare_systems_extended()
        
        print(f"\nğŸ’¡ å»ºè®®:")
        print("1. ä½¿ç”¨å®é™…çš„RLç®—æ³•ï¼ˆå¦‚PPOï¼‰è€ŒééšæœºåŠ¨ä½œè¿›è¡Œè®­ç»ƒ")
        print("2. å¢åŠ è®­ç»ƒæ—¶é—´å’Œepisodeæ•°é‡")
        print("3. è°ƒæ•´å¥–åŠ±æƒé‡ä»¥é€‚åº”å…·ä½“çš„è®­ç»ƒç›®æ ‡")
        print("4. ç›‘æ§å¥–åŠ±ç»„ä»¶åˆ†è§£ä»¥ä¼˜åŒ–ç­–ç•¥")
        
    except KeyboardInterrupt:
        print(f"\nâŒ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
