#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•æ™ºèƒ½ä½“åˆ†æ•°è¡¨ç°
ä¸“é—¨ç”¨äºè§‚å¯Ÿæ™ºèƒ½ä½“æ˜¯å¦èƒ½åƒåˆ°é£Ÿç‰©
"""
import sys
import os
from pathlib import Path
import numpy as np

# è·¯å¾„è®¾ç½®
root_dir = Path(__file__).parent.parent
build_dir = root_dir / "build" / "Release"
sys.path.insert(0, str(build_dir))
os.environ["PATH"] = f"{str(build_dir)};{os.environ['PATH']}"

from gobigger_gym_env import GoBiggerEnv

def test_random_agent(episodes=10):
    """æµ‹è¯•éšæœºæ™ºèƒ½ä½“çš„åˆ†æ•°è¡¨ç°"""
    print("ğŸ® æµ‹è¯•éšæœºæ™ºèƒ½ä½“åˆ†æ•°è¡¨ç°")
    print("=" * 50)
    
    env = GoBiggerEnv({'max_episode_steps': 1000})
    
    scores = []
    score_deltas = []
    
    for episode in range(episodes):
        obs, info = env.reset()
        total_reward = 0
        steps = 0
        
        print(f"\nğŸš€ Episode {episode + 1} å¼€å§‹...")
        
        while True:
            # éšæœºåŠ¨ä½œ
            action = np.random.uniform(env.action_space_low, env.action_space_high)
            action[2] = int(action[2])
            
            obs, reward, terminated, truncated, info = env.step(action)
            total_reward += reward
            steps += 1
            
            if terminated or truncated:
                if 'final_score' in info:
                    final_score = info['final_score']
                    score_delta = info.get('score_delta', 0)
                    episode_length = info.get('episode_length', steps)
                    
                    scores.append(final_score)
                    score_deltas.append(score_delta)
                    
                    print(f"âœ… Episode {episode + 1} ç»“æŸ:")
                    print(f"   ğŸ“Š æœ€ç»ˆåˆ†æ•°: {final_score:.2f}")
                    print(f"   ğŸ“ˆ åˆ†æ•°å˜åŒ–: {score_delta:+.2f}")
                    print(f"   ğŸ•’ æ­¥æ•°: {episode_length}")
                    print(f"   ğŸ¯ æ€»å¥–åŠ±: {total_reward:.3f}")
                    
                    if score_delta > 0:
                        print(f"   ğŸ‰ æˆåŠŸåƒåˆ°é£Ÿç‰©!")
                    else:
                        print(f"   ğŸ˜¢ æ²¡æœ‰åƒåˆ°é£Ÿç‰©")
                else:
                    print(f"   âŒ æ— æ³•è·å–åˆ†æ•°ä¿¡æ¯")
                break
    
    # æ€»ç»“ç»Ÿè®¡
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“:")
    if scores:
        print(f"   å¹³å‡æœ€ç»ˆåˆ†æ•°: {np.mean(scores):.2f}")
        print(f"   å¹³å‡åˆ†æ•°å˜åŒ–: {np.mean(score_deltas):+.2f}")
        print(f"   æœ€é«˜åˆ†æ•°: {max(scores):.2f}")
        print(f"   æœ€ä½åˆ†æ•°: {min(scores):.2f}")
        
        success_count = sum(1 for delta in score_deltas if delta > 0)
        print(f"   æˆåŠŸåƒåˆ°é£Ÿç‰©çš„è½®æ¬¡: {success_count}/{len(score_deltas)}")
        print(f"   æˆåŠŸç‡: {success_count/len(score_deltas)*100:.1f}%")
    else:
        print("   âŒ æœªè·å–åˆ°æœ‰æ•ˆåˆ†æ•°æ•°æ®")

def test_trained_agent(model_path, episodes=5):
    """æµ‹è¯•è®­ç»ƒå¥½çš„æ™ºèƒ½ä½“"""
    try:
        from stable_baselines3 import PPO, DQN, A2C
        
        print(f"ğŸ¤– æµ‹è¯•è®­ç»ƒå¥½çš„æ™ºèƒ½ä½“: {model_path}")
        print("=" * 50)
        
        # åŠ è½½æ¨¡å‹
        if 'PPO' in model_path:
            model = PPO.load(model_path)
        elif 'DQN' in model_path:
            model = DQN.load(model_path)
        elif 'A2C' in model_path:
            model = A2C.load(model_path)
        else:
            print("âŒ æ— æ³•è¯†åˆ«æ¨¡å‹ç±»å‹")
            return
        
        env = GoBiggerEnv({'max_episode_steps': 1000})
        
        scores = []
        score_deltas = []
        
        for episode in range(episodes):
            obs, info = env.reset()
            total_reward = 0
            steps = 0
            
            print(f"\nğŸš€ Episode {episode + 1} å¼€å§‹...")
            
            while True:
                action, _states = model.predict(obs, deterministic=True)
                obs, reward, terminated, truncated, info = env.step(action)
                total_reward += reward
                steps += 1
                
                if terminated or truncated:
                    if 'final_score' in info:
                        final_score = info['final_score']
                        score_delta = info.get('score_delta', 0)
                        episode_length = info.get('episode_length', steps)
                        
                        scores.append(final_score)
                        score_deltas.append(score_delta)
                        
                        print(f"âœ… Episode {episode + 1} ç»“æŸ:")
                        print(f"   ğŸ“Š æœ€ç»ˆåˆ†æ•°: {final_score:.2f}")
                        print(f"   ğŸ“ˆ åˆ†æ•°å˜åŒ–: {score_delta:+.2f}")
                        print(f"   ğŸ•’ æ­¥æ•°: {episode_length}")
                        print(f"   ğŸ¯ æ€»å¥–åŠ±: {total_reward:.3f}")
                        
                        if score_delta > 0:
                            print(f"   ğŸ‰ æˆåŠŸåƒåˆ°é£Ÿç‰©!")
                        else:
                            print(f"   ğŸ˜¢ æ²¡æœ‰åƒåˆ°é£Ÿç‰©")
                    break
        
        # æ€»ç»“ç»Ÿè®¡
        print("\n" + "=" * 50)
        print("ğŸ“Š è®­ç»ƒæ™ºèƒ½ä½“æµ‹è¯•æ€»ç»“:")
        if scores:
            print(f"   å¹³å‡æœ€ç»ˆåˆ†æ•°: {np.mean(scores):.2f}")
            print(f"   å¹³å‡åˆ†æ•°å˜åŒ–: {np.mean(score_deltas):+.2f}")
            print(f"   æœ€é«˜åˆ†æ•°: {max(scores):.2f}")
            print(f"   æœ€ä½åˆ†æ•°: {min(scores):.2f}")
            
            success_count = sum(1 for delta in score_deltas if delta > 0)
            print(f"   æˆåŠŸåƒåˆ°é£Ÿç‰©çš„è½®æ¬¡: {success_count}/{len(score_deltas)}")
            print(f"   æˆåŠŸç‡: {success_count/len(score_deltas)*100:.1f}%")
        
    except ImportError:
        print("âŒ éœ€è¦ stable-baselines3 æ¥æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹")

def main():
    print("ğŸ§ª GoBigger æ™ºèƒ½ä½“åˆ†æ•°æµ‹è¯•å™¨")
    print("ç”¨äºå¿«é€Ÿè§‚å¯Ÿæ™ºèƒ½ä½“æ˜¯å¦èƒ½åƒåˆ°é£Ÿç‰©")
    print("=" * 60)
    
    print("ğŸ¯ é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. æµ‹è¯•éšæœºæ™ºèƒ½ä½“ (10è½®)")
    print("2. æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹")
    print("3. å¿«é€Ÿæµ‹è¯•éšæœºæ™ºèƒ½ä½“ (3è½®)")
    
    try:
        choice = input("è¯·é€‰æ‹© (1-3): ").strip()
        
        if choice == "1":
            test_random_agent(episodes=10)
        elif choice == "2":
            # æŸ¥æ‰¾å¯ç”¨çš„æ¨¡å‹
            models_dir = Path("models")
            checkpoints_dir = Path("checkpoints")
            
            model_files = []
            if models_dir.exists():
                model_files.extend(list(models_dir.glob("*.zip")))
            if checkpoints_dir.exists():
                model_files.extend(list(checkpoints_dir.glob("*.zip")))
            
            if model_files:
                print("ğŸ“ å¯ç”¨æ¨¡å‹:")
                for i, model_file in enumerate(model_files):
                    print(f"   {i+1}. {model_file}")
                
                model_choice = input("é€‰æ‹©æ¨¡å‹ç¼–å·: ").strip()
                try:
                    model_idx = int(model_choice) - 1
                    if 0 <= model_idx < len(model_files):
                        test_trained_agent(str(model_files[model_idx]))
                    else:
                        print("âŒ æ— æ•ˆçš„æ¨¡å‹ç¼–å·")
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            else:
                print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
                print("ğŸ’¡ è¯·å…ˆè¿è¡Œ train_rl_agent.py è®­ç»ƒæ¨¡å‹")
        elif choice == "3":
            test_random_agent(episodes=3)
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æµ‹è¯•å·²å–æ¶ˆ")
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

if __name__ == "__main__":
    main()
